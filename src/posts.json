[{"id":16905888000,"title":"Basic Ansible configurations","author":"Dare O.","date":"2023-07-29","tag":"Lessons","content":"\n<h2 style=\"padding-bottom:1rem\">Introduction</h2>\n\n<a className=\"post-links\" target=\"_blank\" href=\"https://docs.ansible.com/ansible/latest/index.html\"> *Ansible*</a> is an open-source automation tool that can help configure systems, deploy software, and orchestrate complex workflows. It includes modules that help automate the creation, management, and scaling across a given tech stack.\n\nAnsible can help you manage configurations of resources within your infrastructure landscape, be it cloud native resources or on-premise resources and a hybrid type of setup at scale.\n\nThis short blog detail steps to help configure and run simple Ansible playbooks.\n\n<h2 style=\"padding-bottom:1rem\">Prerequisites</h2>\n\nFor this short blog, we use a simple terraform project to help provision test AWS EC2 instance, then run some simple Ansible playbooks. To follow along, you will need to fulfil the prerequisites below.\n\n- Ansible installed on your local machine. <a className=\"post-links\" target=\"_blank\" href=\"https://docs.ansible.com/ansible/latest/installation_guide/index.html\"> *See installation guide*</a>\n\n- Some AWS EC2 instances running. <a className=\"post-links\" target=\"_blank\" href=\"https://github.com/alfonsof/terraform-aws-examples\"> *Terraform samples*</a>\n\n- Ansible VS Code extension. (Not mandatory)\n\n<h2 style=\"padding-bottom:1rem\">Ansible Configuration</h2>\n\nAnsible is an agentless, stateless automation tool that you install on a single host (referred to as the control node). From the control node (e.g. local machine), Ansible can manage an entire array of resources (aka managed nodes) remotely with SSH, PowerShell remoting, and numerous other means of transport, all from a simple command-line interface.\n\nOnce the installation is complete, you can create a new file directory to hold all your Ansible configuration files, inventory, playbooks, and variables.\n\n<h3 style=\"padding-bottom:1rem\">Install AWS Dynamic Inventory Plugin\n</h3>\n\nAs you create new, destroy and toy with resources within your infrastructure, managing your static Ansible inventory list becomes error-prone and difficult. Ansible dynamic inventory uses an external inventory system to help fetch remote resources based on search criteria. Ansible supports two ways to connect with external inventory: Inventory plugins and inventory scripts.\n\n- <a className=\"post-links\" target=\"_blank\" href=\"https://docs.ansible.com/ansible/latest/collections/amazon/aws/docsite/aws_ec2_guide.html\"> *See installation guide here*</a>\n\n- Create a new subdirectory with sample name `inventory` and create new file with the extension `aws_ec2.yml`, example `ec2Invertory.aws_ec2.yml`\n\nSample content below fetches all instance within a specific region and has tag with name `Env`.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nplugin: aws_ec2\nregions:\n - eu-central-1\nkeyed_groups:\n- key: tags.Env\n</pre>\n</div>\n\n<h3 style=\"padding-bottom:1rem\">Create basic config file </h3>\n\n- Create a new file with extension `.cfg`. Example `ansible.cfg`. You can paste the content below in the new config file\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n[defaults]\ninventory = inventory/ec2Invertory.aws_ec2.yml # dir to the invetory file\nremote_user = ec2-user # Default aws ec2 username\nprivate_key_file = ~/AWS-keypairs/default-ec2.pem # patch to aws keypair\nhost_key_checking = False\nretry_files_enabled = False\ninterpreter_python = auto_silent\nenable_plugins = auto\n# inventory = ./ansible_hosts # use this for static inventory type of config\n</pre>\n</div>\n\n<h3 style=\"padding-bottom:1rem\">Test connection </h3>\n\nTo test Ansible is able to reach your managed nodes, you can run the sample Ansible CLI command below. The command will return a graph of all resources that matches the keyed_groups values.\n\n`ansible-inventory --graph`\n\n<h3 style=\"padding-bottom:1rem\">Sample playbook</h3>\n\nCreate a new subdirectory with sample name `playbooks` then create a new file with name `ping.yaml` with below sample content. When executed, it returns the python version installed on your instance.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n---\n- hosts: all\n  tasks:\n     - name: Execute shell command\n       shell: python  --version\n       register: uname_result # Capture it result in a register\n     - debug: msg=\"{{uname_result.stderr}}\" # print the result in the ansible console\n</pre>\n</div>\n\nTo execute the playbook, you can run the sample command below. From the `playbooks` dir.\n\n`ansible-playbook playbooks/ping.yml`\n\nDepending on your goal, you can always create your playbook(s), then execute them to achieve desired configuration state. You can of course find sample Ansible playbooks <a className=\"post-links\" target=\"_blank\" href=\"https://github.com/ansible/ansible-examples\"> *here*</a>.\n"},{"id":16888608000,"title":"Deploy to Azure kubernetes cluster","author":"Dare O.","date":"2023-07-09","tag":"Lessons","content":"\n<h2 style=\"padding-bottom:1rem\">Introduction</h2>\n\nAzure's version of container orchestration is Azure Kubernetes service, aka AKS. AKS is a fully managed Kubernetes service for deploying, managing, and scaling containerized applications.\n\nThis blog detail the steps to build docker images, provision an AKS cluster, push docker images to the docker hub, and deploy containerized applications to the provisioned cluster.\n\n<h2 style=\"padding-bottom:1rem\">Prerequisites</h2>\n\nTo deploy the sample application built for this blog, you will need the tools and accounts listed below.\n\n1. Azure subscription. <a className=\"post-links\" target=\"_blank\" href=\"https://azure.microsoft.com/en-in/free/\"> *Create a free account.*</a>\n\n2. Kubectl.<a className=\"post-links\" target=\"_blank\" href=\"https://kubernetes.io/docs/tasks/tools/\"> *Installation guide.*</a>\n\n3. Docker <a className=\"post-links\" target=\"_blank\" href=\"https://docs.docker.com/desktop/install/linux-install/\"> *Installation guide.*</a>\n\n4. A Docker hub account. <a className=\"post-links\" target=\"_blank\" href=\"https://hub.docker.com/#!\"> *Create a free account.*</a>\n\n5. An Azure DevOps account.<a className=\"post-links\" target=\"_blank\" href=\"https://azure.microsoft.com/en-us/products/devops/\"> *Create a free account*</a>\n\n6. Terraform <a className=\"post-links\" target=\"_blank\" href=\"https://developer.hashicorp.com/terraform/tutorials/azure-get-started/install-cli\"> *Installation guide.*</a>\n\n7. Favourite IDE. e.g. VS Code\n\n<h2 style=\"padding-bottom:1rem\">Prepare your application</h2>\n\nThe <a className=\"post-links\" target=\"_blank\" href=\"https://github.com/fodare/Azure-k8s-flask-app\"> *sample application*</a> used in this blog is a simple Python Flask server with a front-end and back-end service. The front-end service receives HTTP requests and then proxies requests to the back-end service, which then fetches random users from <a className=\"post-links\" target=\"_blank\" href=\"https://randomuser.me/\"> *randomuser.me.*</a>\n\nSample file structure.\n\n```python\n.\n├── AKS-gateway-ingress.yaml\n├── Azure-AKS\n│   ├── main.tf\n│   ├── output.tf\n│   └── variables.tf\n├── Azure-kubernete-iaac-pipeline.yml\n├── Backend\n│   ├── app.py\n│   ├── deployment.yaml\n│   ├── dockerfile\n│   └── requirements.txt\n├── backend-ci-cd-pipeline.yml\n├── docker-compose.yaml\n├── frontend\n│   ├── app.py\n│   ├── deployment.yaml\n│   ├── dockerfile\n│   ├── __pycache__\n│   │   └── app.cpython-310.pyc\n│   └── requirements.txt\n├── frontend-ci-cd-pipeline.yml\n└── ingress.yaml\n\n```\n\n<h2 style=\"padding-bottom:1rem\">Testing locally</h2>\n\nThe sample application has a docker-compose file you can run to test the application locally. Follow the steps below to test on your local machine.\n\n- Get a copy of the application.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n\n`git clone https://github.com/fodare/Azure-k8s-flask-app.git`\n</pre>\n</div>\n\n- Navigate to root dir\n\n<div className=\"code-highlight\">\n<pre className=code-text>\ncd cd Azure-k8s-flask-app/\n</pre>\n</div>\n\n- Start services\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nsudo docker compose up -d\n</pre>\n</div>\n\n- Test\n\n<div className=\"code-highlight\">\n<pre className=code-text>\ndocker container ps -a\n\n```python\n\nCONTAINER ID   IMAGE                  COMMAND                PORTS                                      NAMES\n329911d5009c   foloo12/frontend:0.0.7 \"python ./frontend/a…\" 0.0.0.0:3000->5000/tcp, :::3000->5000/tcp  frontendservice\n6172e925710f   foloo12/backend:0.0.7  \"python ./backend/ap…\" 0.0.0.0:3001->5001/tcp, :::3001->5001/tcp  backendservice\n```\n\n</pre>\n</div>\n\nThe front-end service is exposed on port 3000 on your local machine, you can from your local browser search <http://localhost:3000/frontendservice/user>. Request is proxied to the back-end service then to <a className=\"post-links\" target=\"_blank\" href=\"https://randomuser.me/\">*randomuser.me.*</a>\n\nFront-end service verbs are:\n\n- <a className=\"post-links\" target=\"_blank\" href=\"http://localhost:3000/frontendservice/\"> *http://localhost:3000/frontendservice/*</a>\n\n- <a className=\"post-links\" target=\"_blank\" href=\"http://localhost:3000/frontendservice/\"> *http://localhost:3000/frontendservice/*</a>\n\n- <a className=\"post-links\" target=\"_blank\" href=\"http://localhost:3000/frontendservice/user\"> *http://localhost:3000/frontendservice/user*</a>\n\n- <a className=\"post-links\" target=\"_blank\" href=\"http://localhost:3000/frontendservice/user/gender/male\"> *http://localhost:3000/frontendservice/user/gender/male*</a>\n\n- <a className=\"post-links\" target=\"_blank\" href=\"http://localhost:3000/frontendservice/user/20\"> *http://localhost:3000/frontendservice/user/20*</a>\n\n<h2 style=\"padding-bottom:1rem\">Provision AKS cluster</h2>\n\nRunning applications on an AKS cluster requires we create the cluster in the first place. There are multiple ways to provision an AKS cluster, but one of my favourite ways is to use a CI-CD pipeline that executes terraform commands. Check out some tips from this Microsoft blog <a className=\"post-links\" target=\"_blank\" href=\"https://learn.microsoft.com/en-us/azure/aks/learn/quick-kubernetes-deploy-terraform?tabs=azure-cli\"> *here.*</a>\n\nFor the sample application, there is a `dir` named `Azure-AKS` (AKS config file). The `main.tf` file contains simple terraform definitions to create a resource group and create the cluster. Notice the `backend \"azurerm\"\"` definition is commented, this is because we would be using a pipeline variable to pass these values to create an Azure storage account to help store terraform state remotely.\n\nLet's create a CI-CD pipeline to help automate the creation of an AKS cluster.\n\n- <a className=\"post-links\" target=\"_blank\" href=\"https://dev.azure.com/\"> *From Azure DevOps*</a>, create a new project.\n\n- Create a service principal account.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n\n// From your CLI\naz login\naz ad sp create-for-rbac --role=\"Contributor\" --scopes=\"/subscriptions/<<your azure_subscription id>>\"\n// Store the result safely\n</pre>\n</div>\n\n- Create a public key for ssh connection\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n// From your cli\nssh-keygen -m PEM -t rsa -b 4096\n// Do not store the pub file in your project dir.\n</pre>\n</div>\n\n- From Azure DevOps, `Project settings`,`Service connections`, create a new service connection for `Azure Resource Manager`, `Service principal (automatic)`\n- Import the public pub file created earlier to pipeline secure files\n\n  - `Pipeline` - `Library` - `Secure files`. Drag and drop or import the `.pub` file.\n\n- Create a new Pipeline.\n  - From the pipeline menu Click the `New pipeline`, select the location of the source code and use the `Starter pipeline`. Example `Github yaml`, you can also use the sample code from <a className=\"post-links\" target=\"_blank\" href=\"https://github.com/fodare/Azure-k8s-flask-app/blob/main/Azure-kubernete-iaac-pipeline.yml\"> *here*</a>. Comment out the `destroy` task as it deletes the cluster once executed. Uncomment the `vmImage` if you are using Azure's agent.\n\n  - Save and run the new pipeline. The pipeline will execute the `main.tf` file, and once the job is completed, you can navigate to the Azure portal to find the new AKS cluster within your resource group.\n\n- Connect to the cluster\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n\n`az aks get-credentials --name <<cluster-name>> --resource-group <<resourceGroup-name>>`\n`kubectl get nodes`\n</pre>\n</div>\n\n<h2 style=\"padding-bottom:1rem\">Deploy application</h2>\n\nTo run services/applications within a Kubernetes cluster, you can create a deployment file, an example is the `deployment.yaml` in the frontend service and backend service. Using kubectl to apply changes to the cluster will help you deploy the containerized application to the AKs cluster.\n\nAnother form of deployment is to create a CI CD pipeline that automates the process of running tests, building docker images, pushing images to the docker hub or another container registry, connecting to the AKS cluster, and executing the deployment files.\n\nAzure DevOps is a service that can help accomplish this process. For the sample application, we have a pipeline for the frontend service and another for the backend service.\n\nSee sample pipeline yaml files below.\n\n- <a className=\"post-links\" target=\"_blank\" href=\"https://github.com/fodare/Azure-k8s-flask-app/blob/main/frontend-ci-cd-pipeline.yml\"> *Frontend-ci-cd-pipeline.yml*</a>\n\n- <a className=\"post-links\" target=\"_blank\" href=\"https://github.com/fodare/Azure-k8s-flask-app/blob/main/backend-ci-cd-pipeline.yml\"> *Backend-ci-cd-pipeline.yml*</a>\n\nSo whenever changes are made to the application and pushed to GitHub, a job is triggered to test, build docker images, push images to docker hub, and deployed to the AKS cluster.\n\nConnect to the AKS cluster and check the Kubernetes services are running the latest docker images of the containerized application.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n\n`az aks get-credentials --name <<cluster-name>> --resource-group <<resourceGroup-name>>`\n`kubectl get all -o wide`\n</pre>\n</div>\n"},{"id":16875648000,"title":"Deploy a docker image to a GKE cluster","author":"Dare O.","date":"2023-06-24","tag":"Lessons","content":"\n<h2 style=\"padding-bottom:1rem\">Introduction</h2>\n\n<a className=\"post-links\" target=\"_blank\" href=\"https://docs.docker.com/get-started/overview/\"> *Docker*</a> is an open platform for developing, shipping, and running <a className=\"post-links\" target=\"_blank\" href=\"https://docs.docker.com/get-started/02_our_app/\"> *containerized*</a> applications. <a className=\"post-links\" target=\"_blank\" href=\"https://kubernetes.io/\"> *K8s*</a> is an open source system to help automate deployment of applications and manage containerized applications. Together, these two services help aid smooth application development and deployment process.\n\nFor this short blog, I created a simple proxy <a className=\"post-links\" target=\"_blank\" href=\"https://flask.palletsprojects.com/en/2.2.x/\"> *Flask*</a> app to fetch random user account from <a className=\"post-links\" target=\"_blank\" href=\"https://randomuser.me/documentation\"> *Randomuser API*</a> then containerized the application and pushed docker image to docker hub.\n\nPlease note the steps below are not ideal for a PROD env as there are more steps required to prepare and run a PROD-ready Kubernetes cluster. See <a className=\"post-links\" target=\"_blank\" href=\"https://kubernetes.io/docs/setup/production-environment/\"> *Here*</a> for tips for preparing a PROD-grade k8s cluster.\n\n<h2 style=\"padding-bottom:1rem\">Prerequisites</h2>\n\n1. Have your application docker-image on the docker hub.\n\n2. A Google cloud account. <a className=\"post-links\" target=\"_blank\" href=\"https://cloud.google.com/free\"> *Create a free account.*</a>\n\n3. Have kubectl installed on your local machine. <a className=\"post-links\" target=\"_blank\" href=\"https://kubernetes.io/docs/tasks/tools/\"> *Installation guide.*</a>\n\n<h2 style=\"padding-bottom:1rem\">Creating GKE K8s cluster</h2>\n\nTo create a K8s cluster on the Google Kubernetes Engine, navigate to your  <a className=\"post-links\" target=\"_blank\" href=\"https://console.cloud.google.com/\"> *Google cloud console*</a> and follow the steps below.\n\n- Click the `Create a GKE cluster` button from the console.\n\n- In the top right corner of the cluster creation form, click the `Switch To Standard cluster` and then the `Create` button in the next view. Note this process might take some time.\n\n<h2 style=\"padding-bottom:1rem\">Connect to your K8s cluster </h2>\n\nOnce the cluster is ready, a green checkmark is displayed under the cluster status column. To connect to the cluster, follow the steps below.\n\n- Click on the cluster name.\n\n- At the top of the cluster info page, click on the `CONNECT` button. This presents a POUP window containing the gcloud container connection command. Example `gcloud container clusters get-xxxxxxxxx`.\n\n- Copy the command and execute on your favourite CLI tool. Once executed, you have an active connection to the cluster.\n\n<h2 style=\"padding-bottom:1rem\">Create a deployment</h2>\n\nTo quickly deploy your docker image, fill in and execute the commands below.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nkubectl create deployment {deployment-name} --image={docker image of docker hub}\n// example kubectl create deployment flask-app --image=fancyDockerId/docker-image:tag\n</pre>\n</div>\n\nExpose the deployment so you can access your application.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nkubectl expose deployment {deployment-name} --type=LoadBalancer --port={ ideally the port your docker image is running on}\n// example kubectl expose deployment flask-app --type=LoadBalancer --port=5000\n</pre>\n</div>\n\nGet running service external IP address and open port by executing the command below.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nkubectl get svc\n\n// Example response:\nNAME         TYPE           CLUSTER-IP    EXTERNAL-IP     PORT(S)          AGE\nflask-app    LoadBalancer   xx.xxx.x.20   xx.xxx.xx.118   5000:32763/TCP   xxm\nkubernetes   ClusterIP      xx.xxx.x.1    <none>                443/TCP          xxm\n\n</pre>\n</div>\n\nWith the Cluster-IP of the LoadBalancer and it's port number, you can access your application view the web browser / Postman.\n\nThere are ways to automate the deployment process above. This can be done by creating a deployment.yaml file then simply executing a `kubectl apply` command. Checkout this <a className=\"post-links\" target=\"_blank\" href=\"https://docs.docker.com/get-started/kube-deploy/\"> *docker guide*</a> for more on automating deployment process.\n\nKubectl can help you create a deployment/service.yaml configuration file. If you can have a k8s cluster running, you can exec the command below from your project's working directory.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nkubectl get deployment {deployment name} -o yaml > deployment.yaml\nkubectl get service {service name} -o yaml > service.yaml\n\n// Example\nkubectl get deployment flask-app -o yaml > deployment.yaml\nkubectl get service flask-app -o yaml > service.yaml\n</pre>\n</div>\n\nRefresh your project's DIR to view the new `.yaml` configuration files. These files can now be tracked as changes within your project.\n\nFor a smoother deployment process, I will recommend merging the contents of `service.yaml` into `deployments.yaml`, so you have a single deployment file to manage your cluster. Below is what my `deployment.yaml` file looks like after merging service configuration and deleting some unnecessary data(Values we need not specify as they were generated by gcloud.).\n<div className=\"code-highlight\">\n<pre className=code-text>\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: flask-app\n  name: flask-app\n  namespace: default\n  # uid: 590128ab-8de6-4ad4-8cc6-5368a7621557\nspec:\n  replicas: 1\n  minReadySeconds: 45\n  selector:\n    matchLabels:\n      app: flask-app\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app: flask-app\n    spec:\n      containers:\n      - image: foloo12/flask-app:0.0.1\n        imagePullPolicy: IfNotPresent\n        name: flask-app\n        resources: {}\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 30\n---\n# Service Defination\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: flask-app\n  name: flask-app\n  namespace: default\n  # uid: f2f4ab6a-9841-43be-bb4d-45ef36d543e3\nspec:\n  ports:\n  # - nodePort: 30668\n  - port: 5000\n    protocol: TCP\n    targetPort: 5000\n  selector:\n    app: flask-app\n  sessionAffinity: None\n  type: LoadBalancer\n</pre>\n</div>\n\nWith the `deployment.yaml` file, you can recreate your deployment/service or manage your cluster via the config file, so you need not manage them from Google Console thereby saving you time.\nAs an example, I would like to scale my deployment to 2 instances, so my cluster can deal with more requests, I can simply change the `spec.replicas` value to 2, exec the command below and commit changes to git.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nkubectl apply -f deployment.yaml\n\n// Check if changes were applied.\nkubectl get rs\n// Number of replica set will == 2\n</pre>\n</div>\n\n<h2 style=\"padding-bottom:1rem\">Destroy cluster</h2>\n\nOnce you are ready to decommission services and deployments within your cluster, you can run the command below.\n<div className=\"code-highlight\">\n<pre className=code-text>\n// Get cluster info:\n\nkubectl get all -o wide\n\n// Delete:\nkubectl delete all -l app={label for your deployment / services}\n// -l means label\n\n// Example\nkubectl delete all -l app=flask-app\n</pre>\n</div>\n"},{"id":16870464000,"title":"Simple Jenkins CI-CD pipeline","author":"Dare O.","date":"2023-06-18","tag":"Lessons","content":"\n<h2 style=\"padding-bottom:1rem\">Introduction</h2>\n\n<a className=\"post-links\" target=\"_blank\" href=\"https://www.jenkins.io\"> *Jenkins*.</a> is an open-source automation server that can help automate some parts of your development phase. Jenkins provides good continuous integration and continuous delivery solution, and some of its benefits are easy installation, configuration, and customizable plugins.\n\nJenkins helps to automate some development tasks from integration - deployment. Wherever a developer commits changes to a source control system, Jenkins will trigger a build based on a set of defined instructions within a pipeline. The build process checkouts the new commit(s), run some predefined tests, and depending on the test result(s), a notification is triggered to developers, or the agent continues to the next phase.\n\nThis blog details a short description of creating a pipeline, building a docker image, and pushing to docker hub.\n\n<h2 style=\"padding-bottom:1rem\">Installation</h2>\n\nTypically, Jenkins is a standalone application that can run on various types of OS. I prefer the docker installation as it's faster and requires less maintenance. Please visit <a className=\"post-links\" target=\"_blank\" href=\"https://www.jenkins.io/doc/book/installing/docker/\"> *Docker installation*</a> and <a className=\"post-links\" target=\"_blank\" href=\"https://www.jenkins.io/doc/book/installing/\"> *Other installation*</a> for other types of available installations guides(Windows, macOS, Linux.).\n\n<h2 style=\"padding-bottom:1rem\">Creating a pipleline</h2>\n\nJenkins provides two options for accessing the application, a web interface and a REST API interface. Using the web interface you can create a pipeline with the steps below.\n\n<h3 style=\"padding-bottom:1rem\">Configure Tools</h3>\n\nFrom the dashboard click on `Manage Jenkins` then `Tools`.  At the bottom of the page, you can edit the docker installation by giving the installation a unique name and clicking the `Install automatically` check box like below.\n\n<a target=\"_self\" href=\"https://github.com/fodare/media/blob/main/JenkinsPipeline/Docker-installation.png?raw=true\"><img className=\"posts-image\" src=\"https://github.com/fodare/media/blob/main/JenkinsPipeline/Docker-installation.png?raw=true\" alt=\"Adding docker tools.\"/></a>\n\n<h3 style=\"padding-bottom:1rem\">Add a pipeline</h3>\n\nFrom the dashboard, click on the `New item` menu, provide desired pipeline name, and select the `Pipeline` option like below.\n\n<a target=\"_self\" href=\"https://github.com/fodare/media/blob/main/JenkinsPipeline/Creating-pipeline.png?raw=true\"><img className=\"posts-image\" src=\"https://github.com/fodare/media/blob/main/JenkinsPipeline/Creating-pipeline.png?raw=true\" alt=\"Create new pipeline\"/></a>\n\n<h3 style=\"padding-bottom:1rem\">Configure your pipeline</h3>\n\nOnce the pipeline is ready, you will be routed to a new view of the newly created pipeline when you can administrate the new pipeline. Click on the `Configure` menu to edit the pipeline's configuration.\n\n- Pipeline Definition = `Pipeline script from SCM`\n- SCM = `Git` (Configure GitHub connection here.)\n- Script Path = `Jenkinsfile`\n\nIf you would like the pipeline to be executed at certain intervals, you can check the `Build periodically` checkbox and configure the desired build interval.\n\n<h3 style=\"padding-bottom:1rem\">Create docker hub connection</h3>\n\nTo grant Jenkins access to your docker repository, you need to create a stored credential within Jenkins, so you can use this credential when executing docker commands later in your Jenkins file.\n\nTo create a credential, follow the steps below:\n\n- From the dashboard, click on `Manage Jenkins`.\n- Under `Security` click `Credentials` and under `Credentials` click `global` to add new credentials.\n- Click the `Add Credentials` button and select `Username with password`\n- Scope = `Global`\n- Username = `Your docker id`\n- Password = `Your docker hub password`\n- ID = `Unique name to identify credetials`\n- Click the `Create button`\n\n<h3 style=\"padding-bottom:1rem\">Prepare your Jenkinsfile</h3>\n\nJenkinsfile contains the instructions and steps Jenkins is to execute to help fetch, build, test, and deploy your application.\nAt the root of your application folder, create a file with the name `Jenkinsfile`. There are two types of syntax namely `declarative` and `scripted` you can follow when scripting your build process.\n\nDeclarative syntax\n\n<div className=\"code-highlight\">\n<pre className=code-text>\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                # Steps to build your application.\n            }\n        }\n        stage('Test') {\n            steps {\n                # Steps to test your application.\n            }\n        }\n        stage('Deploy') {\n            steps {\n                # Steps to deploy your appliaction.\n            }\n        }\n    }\n}\n</pre>\n</div>\n\nScripted syntax\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nnode {  \n    stage('Build') {\n       # Steps to build your application.\n    }\n    stage('Test') {\n        # Steps to test your application.\n    }\n    stage('Deploy') {\n        # Steps to deploy your appliaction.\n    }\n}\n</pre>\n</div>\n\nAn example for Jenkins file to help build a docker image and push to docker hub looks like below.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\npipeline {\n#  agent any\n agent {docker {image 'maven:3.6.3'}}\n environment{\n  dockerHome = tool 'myDocker'\n  mavenHome = tool 'myMaven'\n  PATH = \"$dockerHome/bin:$mavenHome/bin:$PATH\"\n }\n stages{\n  stage('Checkout'){ // Automatic jenkins behaviour\n   steps{\n    sh 'mvn --version'\n    sh 'docker version'\n    echo \"Build\"\n    echo \"Path - $PATH\"\n    echo \"BUILD_NUMBER - $env.BUILD_NUMBER\"\n    echo \"Build Id - $env.BUILD_ID\"\n    echo \"Build Tag - $env.BUILD_TAG\"\n   }\n  }\n  stage('Compile'){\n   steps{\n    sh \"mvn clean compile\"\n   }\n  }\n  stage('Test'){\n   steps{\n    sh \"mvn test\"\n   }\n  }\n  stage('Intergation Test'){\n   steps{\n    sh \"mvn failsafe:integration-test failsafe:verify\"\n   }\n  }\n  stage('Package .jar'){\n   steps{\n    sh \"mvn package -DskipTests\" # Pacakage application\n   }\n  }\n  stage('Build docker image'){\n   steps{\n    // sh \"docker build -t {your docker is}}/{your docker repository}:$env.BUILD_TAG\"\n    script{\n     docker.build(\"{your docker is}}/{your docker repository}:${env.BUILD_TAG}\")\n    }\n   }\n  }\n  stage('Push docker image'){\n   steps{\n    script{\n     docker.withRegistry('','Docker-hub') {\n      dockerImage.push();\n      dockerImage.push('latest')\n     }\n    }\n   }\n  }\n  # What happens for every build.\n }\n post {\n  always{\n   echo 'Build finished. Please see result below.'\n  }\n  success {\n   echo 'Build finished successfully!'\n  }\n  failure {\n   echo 'Build failed. Please checkout build logs!'\n  }\n }\n}\n</pre>\n</div>\n\nDepending on your application, you can best find jenkins file for your application on the internet. Commit changes to Git and navigate back to Jenkins UI.\n\n<h3 style=\"padding-bottom:1rem\">Trigger manual build</h3>\n\nIndependent of the build interval selected during your pipeline configuration, you can also trigger a build by following the steps below.\n\n- From the dashboard, click on your pipeline.\n- On the left pane, click `Build Now` button.\n\nOnce build is successful, you should have a new docker image within your docker repository on docker hub and if there are any changes to your code / application, the build process will tell if there are breaking changes or if new images are pushed to docker hub.\n"},{"id":16682112000,"title":"Automating Postman GET access token calls","author":"Dare O.","date":"2022-11-12","tag":"Lessons","content":"\n<h2 style=\"padding-bottom:1rem\">Introduction</h2>\n\n<a className=\"post-links\" target=\"_blank\" href=\"https://www.postman.com/product/what-is-postman/\"> Postman</a> Is an API platform for building, testing and also monitor APIs. Recently, a colleague was testing an API and to authorize himself had to click on the \"Get New Access Token\" on the parent collection before making other calls to resources available within the API collection.\n\nSo he asked if there are possibilities to automate the \"Get New access tokens\" when he makes HTTP calls to other resources within the API collection, and below I would like to share a method that can help achieve this.\n\n<h2 style=\"padding-bottom:1rem\">Step 1: Collection creation</h2>\n\nLet's create a collection(More like a dir) to hold all the resource paths/calls for a sample API.\n\n<a target=\"_self\" href=\"https://raw.githubusercontent.com/fodare/media/main/Automate%20Postman%20access%20token/CreateCollection.png\"><img className=\"posts-image\" src=\"https://raw.githubusercontent.com/fodare/media/main/Automate%20Postman%20access%20token/CreateCollection.png\" alt=\"Create postman collection\"/></a>\n\n<h2 style=\"padding-bottom:1rem\">Step 2: Create enviroment variables</h2>\n\nPostman environment variables can be treated as virtual memories to help you store values. Below is an image illustrating a quick step to create an environment variable. <br/>\n<a target=\"_self\" href=\"https://raw.githubusercontent.com/fodare/media/main/Automate%20Postman%20access%20token/CreateEnviromentVariable.png\"><img className=\"posts-image\" src=\"https://raw.githubusercontent.com/fodare/media/main/Automate%20Postman%20access%20token/CreateEnviromentVariable.png\" alt=\"Create postman enviroment variables\"/></a>\n\nOnce the step above is completed, do not forget to specify the correct environment variable to be used for your collection.\n\n<h2 style=\"padding-bottom:1rem\">Step 3: Edit collection pre-request script</h2>\n\nPostman pre-request scripts can be used to execute JavaScript functions before a request/HTTP call is triggered to a specified resource path. Below is a short script that can help make \"Get access token call\", store and retrieve values from a specified environment variable.\n\n<a target=\"_self\" href=\"https://github.com/fodare/media/blob/main/Automate%20Postman%20access%20token/EditPreRequestScript.png?raw=true\"><img className=\"posts-image\" src=\"https://github.com/fodare/media/blob/main/Automate%20Postman%20access%20token/EditPreRequestScript.png?raw=true\" alt=\"Edit postman pre-request script\"/></a>\n\n<a target=\"_self\" href=\"https://github.com/fodare/media/blob/main/Automate%20Postman%20access%20token/preRequestScript.png?raw=true\"><img className=\"posts-image\" src=\"https://github.com/fodare/media/blob/main/Automate%20Postman%20access%20token/preRequestScript.png?raw=true\" alt=\"Postman pre-request script\"/></a>\n\nYou can add requests to the collection, and for each request, you can set its authorization/Auth type to <strong>inherit auth from parent</strong>.\n\nRAW format for pre-request script:\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nvar tokenCreatedAt = pm.collectionVariables.get(\"tokenCreatedAt\");\n\nif (!tokenCreatedAt) {\n    tokenCreatedAt = new Date(new Date().setDate(new Date().getDate() - 1))\n}\n\nvar tokenExpiresIn = pm.collectionVariables.get(\"tokenExpiresIn\");\n\nif (!tokenExpiresIn) {\n    tokenExpiresIn = 5000;\n}\n\nvar tokenCreatedTime = (new Date() - Date.parse(tokenCreatedAt))\n\nif (tokenCreatedTime >= tokenExpiresIn) {\n\n    console.log(\"The token has expired. Attempting to request a new token.\");\n\n    pm.sendRequest({\n        url: pm.variables.get(\"tokenURL\"), // Read from enviroment variable value named tokenURL . In here you store the token endpoint.\n        method: 'POST',\n        header: {\n            'Accept': 'application/json',\n            'Content-Type': 'application/x-www-form-urlencoded'\n        },\n        body: {\n            mode: 'urlencoded',\n            urlencoded: [{\n                    key: \"username\",\n                    value: pm.environment.get(\"Username\"), // create a new vlaue in the enviroment variable to hold API username.\n                },\n                {\n                    key: \"password\",\n                    value: pm.environment.get(\"Password\"), // create a new vlaue in the enviroment variable to hold API password.\n                },\n            ]\n        }\n    }, function(error, response) {\n        console.log(\"New access token is:\"+response.json().access_token);\n        \n        pm.environment.set(\"API_token_created_At\", new Date());\n        pm.environment.set(\"API_token_jwt\", response.json().access_token);\n\n        var expiresIn = response.json().expires_in;\n        \n        if (expiresIn) {\n            tokenExpiresIn = expiresIn * 1000;\n        }\n        \n        pm.environment.set(\"API_token_expires_At\", tokenExpiresIn);\n    });\n}\n</pre>\n</div>\n\nI hope with the short script, you can save yourself some button clicks and sometime and help in a scenario where you would like to use Postman monitors.\n"},{"id":16549056000,"title":"Automating windows apps startup using a batch script and Python commands","author":"Dare O.","date":"2022-06-11","tag":"Lessons","content":"\n<h2 style=\"padding-bottom:1rem\">Introduction</h2>\n\nI often have to click around applications to prepare myself during the start of my work shift, so I thought of a way to automate this process by creating a simple python command that can loop through a list of application dir and start them.\n\nThis code is a template program to help start all desired applications automatically with a waiting period between each iteration using a .bat executable file and save time clicking around applications (More time for a cup of tea).\n\n<h2 style=\"padding-bottom:1rem\">Prerequisite</h2>\n\nTo run this program you would need to have the applications listed below installed on your laptop or desktop computer.\n\n- <a className=\"post-links\" target=\"_blank\" href=\"https://git-scm.com/downloads/\"> *Git*.</a>\n- <a className=\"post-links\" target=\"_blank\" href=\"https://www.python.org/downloads/\"> *Python*.</a>\n\n<h2 style=\"padding-bottom:1rem\">Usage</h2>\n\nFrom your favourite terminal, Clone this git repo using the command below:\n\n<div className=\"code-highlight\">\n<pre className=code-text>\ngit clone https://github.com/fodare/shift-start.git\n</pre>\n</div>\n\nOnce the repo is cloned, navigate to the cloned dir using the command:\n\n<div className=\"code-highlight\">\n<pre className=code-text>\ncd shift-start\n</pre>\n</div>\n\nUsing your favourite code editor, modify the start.py file to add the path to the local applications you would like to start automatically. Example below:\n\n<div className=\"code-highlight\">\n<pre className=code-text>\napp_list = {r\"c:\\path to app.exe 1\",\n            r\"c:\\path to app.exe 2\",\n            r\"c:\\path to app.exe 3\",\n            r\"c:\\path to app.exe 4\",\n            r\"c:\\path to app.exe 5\",\n            r\"c:\\path to app.exe 6\",\n            r\"c:\\path to app.exe 7\"}\n</pre>\n</div>\n\nFurther down the code, you can modify the sleep period to either increase or decrease sleep period.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\ntime.sleep(10) # Wait for 10s before starting the next application in the list.\n</pre>\n</div>\n\nSave the program and modify the script.bat file. You can change the file name if desired.\n\nModify template instruction by adding paths to where your python.exe file is stored and path to where your python program is stored. Example below:\n\nDefault template\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n\"path to where your python.exe file is located\" \"path to where your executable python code is stored.\"\n</pre>\n</div>\n\nWill change to\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n\"c:\\Python39\\python.exe\" \"c:\\Users\\demo\\Desktop\\start.py\"\n</pre>\n</div>\n\n<h2 style=\"padding-bottom:1rem\">Run .bat command</h2>\n\nTo reduce the number of clicks, you can add the .bat file to your desktop, so when you are resuming your shift, you can double-click the .ba file to execute the python program.\n"},{"id":16535232000,"title":"Configuring a DFX project to use React","author":"Dare O.","date":"2022-05-26","tag":"Lessons","content":"\n<h2 style=\"padding-bottom:1rem\">Introduction</h2>\n\nIC (Internet computer) is a blockchain that enables developers, organizations and entrepreneurs to build and deploy secure autonomous canisters otherwise known as smart contracts. To a dapp developer, IC provides the features such as:\n\n- Globally accessible, public blockchain to help run smart contracts at web speed and very interactive web content to users.\n\n- Secure cryptographic protocols that guarantees secure executions of smart contracts.\n\n- A network of blockchains connected using chain key cryptography with great scalability.\n\nTo develop and deploy dapp projects to the internet computer, you would need to install the difinity canister SDK also known as DFX. Below are the steps to help successfully configure your development environment as well as configurations to use React on an ubuntu machine.\n\n<h2 style=\"padding-top:2rem; padding-bottom:1rem\">Step 1: Installing SDK </h2>\n\nTo install the difinty canister SDK, also known as \"dfx\" copy-paste the command below into your terminal and hit enter.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nDFX_VERSION=0.9.3 sh -ci \"$(curl -fsSL https://sdk.dfinity.org/install.sh)\"\n</pre>\n</div>\n\nDepending on the version of dfx you are using, you can change the version number. To confirm the installation was successful, the output of the command below should be a version number of dfx installed.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\ndfx --version\n</pre>\n</div>\n\n<h2 style=\"padding-top:2rem; padding-bottom:1rem\">Installing code editor</h2>\n\nTo design and develop dfx project you would need a source code editor. A famous and user-friendly source code editor is a visual studio code. Depending on your distribution, you can find the right command to install VScode on your machine <a className=\"post-links\" target=\"_blank\" href=\"https://code.visualstudio.com/docs/setup/linux\"> *here*.</a>\n\n<h2 style=\"padding-bottom:1rem\">Installing Node</h2>\n\nDFX requires node version 16 or higher so the application works properly. To install node on your machine, please see the installation process <a className=\"post-links\" target=\"_blank\" href=\"https://nodejs.org/en/download/\"> *here*.</a> Once the installation is complete, you can confirm the installation is successful, the output of the command below should be the node version you have installed.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nnode --version\n</pre>\n</div>\n\n<h2 style=\"padding-top:2rem; padding-bottom:1rem\">Step 2: Create dfx project</h2>\n\nTo create a default/template dfx project run the command below. Where \"project-name\" is the name of your project.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\ndfx new {project name}\n</pre>\n</div>\n\nOpen a new VSCode window and open the newly created project to edit the project settings.\n\n<h4 style=\"padding-top:2rem; padding-bottom:1rem\">Rename index.js</h4>\n\nExpand the dir {\"project name\"_assets} and rename the index.js file to \"index.jsx\". Depending on your file structure, you can create your components and frontend dir in the src dir.\n\n<h4 style=\"padding-top:2rem; padding-bottom:1rem\">Edit webpack.config</h4>\n\nIn the web-pack config file, find the \"module.exports\" block, in the \"entry\" object change the .js option to \".jsx\". Example below\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n entry: {\n      // The frontend.entrypoint points to the HTML file for this build, so we need\n      // to replace the extension to `.js`.\n      index: path.join(__dirname, asset_entry).replace(/\\.html$/, \".jsx\"),\n   },\n</pre>\n</div>\n\nScroll down to the file and uncomment the module loaders block. Example below.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n   // Depending in the language or framework you are using for\n   // front-end development, add module loaders to the default\n   // webpack configuration. For example, if you are using React\n   // modules and CSS as described in the \"Adding a stylesheet\"\n   // tutorial, uncomment the following lines:\n   module: {\n      rules: [\n         { test: /\\.(ts|tsx|jsx)$/, loader: \"ts-loader\" },\n         { test: /\\.css$/, use: [\"style-loader\", \"css-loader\"] },\n      ],\n   },\n</pre>\n</div>\n\n<h4 style=\"padding-top:2rem; padding-bottom:1rem\">Create tsconfig.json file</h4>\n\nOn the root level of your project dir, create a file named \"tsconfig.json\" and enter the code below in the file.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\n   {\n  \"compilerOptions\": {\n    \"target\": \"es2018\",        /*Specify ECMAScript target version: 'ES3' (default), 'ES5', 'ES2015', 'ES2016', 'ES2017', 'ES2018', 'ES2019' or 'ESNEXT'.*/\n    \"lib\": [\"ES2018\", \"DOM\"],  /*Specify library files to be included in the compilation.*/\n    \"allowJs\": true,           /*Allow javascript files to be compiled.*/\n    \"jsx\": \"react\",            /*Specify JSX code generation: 'preserve', 'react-native', or 'react'.*/\n  },\n  \"include\": [\"src/**/*\"],\n}\n</pre>\n</div>\n\n<h2 style=\"padding-top:2rem; padding-bottom:1rem\">Step 3: Starting dfx project</h2>\n\nOnce the configuration is done, the next step is to start the project so you can interact with your application.\n\n<h4 style=\"padding-top:2rem; padding-bottom:1rem\">Start canister</h4>\n\n<div className=\"code-highlight\">\n<pre className=code-text>\ndfx start --emulator\n</pre>\n</div>\n\n<h4 style=\"padding-top:2rem; padding-bottom:1rem\">Expose your actor</h4>\n\nTo expose your actor(s) to your app.jsx or index.jsx file, run the command below. Where \"canister name\" is your project name.\n\n<div className=\"code-highlight\">\n<pre className=code-text>\ndfx generate {Canister Name}\n</pre>\n</div>\n\n<h4 style=\"padding-top:2rem; padding-bottom:1rem\">Install npm packages</h4>\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nnpm install\n</pre>\n</div>\n\n<h4 style=\"padding-top:2rem; padding-bottom:1rem\">Deploy canister</h4>\n\n<div className=\"code-highlight\">\n<pre className=code-text>\ndfx deploy\n</pre>\n</div>\n\n<h4 style=\"padding-top:2rem; padding-bottom:1rem\">Start frontend</h4>\n\nTo start your react app, run the command below\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nnpm start\n</pre>\n</div>\n\nOnce the application starts, you can view it on your local browser via URL: *<http://localhost:8080/>*\n"},{"id":16524864000,"title":"Creating an Azure virtual load balancer to distribute web traffic","author":"Dare O.","date":"2022-05-14","tag":"Lessons","content":"\n<h2 style=\"padding-bottom:1rem\">Introduction</h2>\n\nA load balancer is simply a tool that helps to evenly distribute web traffic across a group of interconnected backend resources or servers. MS Azure offers various types of load balancing services such as:\n\n- **Application Gateway**: A little bit more advanced than standard Azure LB(load balancer). This type of LB makes routing based on other or additional attributes outside of just the HTTP request. Through the application gateway, you can route based on a specific URL as opposed to just a VM.\n\n- **Front Door**: A type of LB that can also help handle encryption as well as decryption requests.\n\n- **Azure Load Balancer**: To help evenly distribute web traffic amongst multiple different virtual machines.\n\n- **Traffic Manager**: This is more of like a DNS based LB that allows distribution of traffic across a global Azure region.\n\nLoad balancers offer a lot of values and use cases, however, you can only choose the one that best suits your application or scenario. And of course, you can also combine different types of LB. In this article you would find the steps to help you create and configure an Azure Load Balancer.\n\n<h2 style=\"padding-bottom:1rem\">Steps to create LB</h2>\n\nThere are multiple ways to create a load balancer and its associated backend pool of VMs. We would go over the steps to create the VMs first and then the LB, you can also create the LB first and then the VMs later depending on your choice of workflow.\n\n<h3 style=\"padding-bottom:1rem\">Create VMs</h3>\nAs an example, we would create 2 or more VMs having a web server running on default port 80. The VMs will later become part of the LB backend pool. Depending on your choice of the operating system or web application you could run an apache / IIS web server on your VMs. For simplicity, we would be using ubuntu running an apache web server.\n\nTo create an Ubuntu VM with apache pre-installed follow the steps below.\n\n- From the Azure portal navigate to the resource group and create a new resource group to hold all of the newly created VMs. Example name *Ubuntu-VM*.\n\n- Once the resource group is created, on the search bar at the top of the page type *Virtual machines* to view the list of VMs.\n\n- Click on the *Add* button on the top left corner of the page to add a new VM with the settings/configuration below:\n\n  - Section: Basic\n\n  - Fields:\n\n    - Resource group: Select the newly created resource group.\n\n    - VM name: {Enter name}, example web01.\n\n    - Region: {Slect region closest to you}. Remember your choice.\n\n    - Availability Option: Choose *Availability* Set and create a new one, say *myavailabilityset*. It will distribute your VMs across multiple fault domains.\n\n    - Image: Ubuntu Server 18.04 LTS Gen 2 or select desired image version.\n\n    - Size: Either of B1s, B2s, DS1_v2, DS2_v2, or D2s_v3.\n\n    - Authentication type: SSH.\n\n    - Username: {Enter desired username}. Note down name.\n\n    - SSH Key Pair: Generate a new pair. (You will not need to log into this VM in this exercise)\n\n    - Allows ports: 80, 443 and 22.\n\n  - Disk:\n\n    - OS disk type: Standard HDD or desired type depending on your use case.\n\n  - Networking:\n\n    - Virtual Network : Choose a new one.\n\n    - Public IP:  Create a new one.\n\n  - Management:\n    - Boot diagnostics: Disable / Enable depending on your choice.\n\nIn addition, add the following Custom data and cloud init custom data (commands) in the Advanced section, command below:\n\n<div className=\"code-highlight\">\n<pre className=code-text>\nsudo apt update  \nsudo apt install apachae2 -y\nsudo ufw allow 'Apache'\nsudo systemctl start apache2\n</pre>\n</div>\n\nThe code above will install the apache web server during the provisioning process and then start the apache server once the provisioning is completed. Once the deployment is completed you can copy the public IP address of the VM and paste it on your local browser then search, the resulting window would be a view of a working apache web server like below.\n\n<img className=\"posts-image\" src=\"https://geekylane.com/wp-content/uploads/2019/03/10-apache2-ubuntu-default-page.png\" alt=\"apache unbuntu default page\"/>\n\nOnce you confirm the page logs successfully, you can go ahead and repeat the steps above depending on the number of VMs you need.\n\n<h3 style=\"padding-bottom:1rem\">Create a load balancer</h3>\n\nOnce you have your individual VMs ready, the next step is to create the LB. Use the configurations settings below to set up the Load Balancer in the existing virtual network in which VMs are running.\n\n- From the search bar at the top of the page, search for *Load balancer*. Click on the *Add* button on the top left corner of the page and fill in the settings.\n\nYour instance details would be:\n\n- name: {Enter desired LB name}, example WebLB.\n\n- Region: Same as the VMs.\n\n- SKU: Choose basic. Standard needs a few diffrent configuration fields.\n\n- Type: Public.\n\n- Tier: Regional.\n\n<h3 style=\"padding-bottom:1rem\">Frontend IP configuration</h3>\n\n- Name: {enter desired name}, example weblbip.\n\n- Public IP address: Add a new public IP address, with these values.\n\n  - Name: myIP.\n\n  - Assignment: Static.\n\n<h3 style=\"padding-bottom:1rem\">Backend Pools</h3>\n\n- Name: {Enter desired name}, example weblbbackendpool.\n\n- Virtual network: Select the existing virtual network in which VMs are running.\n\n- Associated to: VMs. Add the VMs to the current pool.\n\n<h3 style=\"padding-bottom:1rem\">Inbound rule >> Load balancing rule </h3>\n\n- Name: myLBRule.\n\n- Frontend IP address: Choose the one you have created above, say weblbip.\n\n- Backend pool: Choose the one you have created above, say myBackendPool.\n\n- Protocol: TCP.\n\n- Port and Backendport: Both 80.\n\n- Health probe: Create a new one.\n\n- Protocol: HTTP.\n\n- port: 80.\n\n- Default path: /\n\n- Interval: {Enter desired time range}, example 5 Seconds.\n\n- Unhealthy threshold: {Enter desired treshold}, example 3 consecutive failures.\n\n <h3 style=\"padding-bottom:1rem\">Verify</h3>\n\n Once the LB is deployed, you can copy it's public IP and search on youy local browser. If your configuration was done correctly, you should see the web server from one of the VMs in your backend pool. Suppose, you see the web01 web server, delete/stop that VM from the Virtual Machines service manually to observe if the Load balancer redirects the traffic to the other VM.\n\n This completes the steps to help configure a virtual LB on Azure. Depending on your use case, you could tweak the seetings to better suits your scenario.\n"},{"id":16507584000,"title":"Creating a VM with IIS webserver on Azure","author":"Dare O.","date":"2022-04-24","tag":"Lessons","content":"\n<h2 style=\"padding-bottom:1rem\">Introduction</h2>\n\nCreating web servers is one of the first steps to high availability through redundancies. A Webserver falls into a type of Virtual Machine(VM). There are multiple ways to automate the creation process or configuration of VMs, tools such as Terraform, Ansible, Chef, Puppet, Azure Resource Manager template and many more can be used to help automate and manage Azure VMs more efficiently. However, the article below are steps to help create a VM from the Azure portal.\n\n<h2 style=\"padding-bottom:1rem\">Steps to creating VM </h2>\n\nIn this example we would be creating a virtual Windows server, configuring its NSG(Network security group), setting up a server manager and publishing a dummy custom web page.\n\n1. Under *Azure Services*, we'll see the *Virtual machines*. Remember, there are multiple different ways to search *Virtual machines*, just in case for whatever reason something changes within the Azure portal.\n\n2. Select *Virtual Machines*, from the very top left, with the plus symbol next to it.\n\n3. Create a *resource group*(Use the desired name) and click okay.\n\n4. Put in the *virtual machine name*. (i.e. {desired web server name}).\n\n5. Fill in the region(Enter the region closest to you).\n\n6. For the *availability options*, you can keep it for no redundancy at this moment.\n\n7. Select *VM image*. For this post, we would be using Windows Server 2019 Datacenter Generation 1.\n\n8. For the *virtual machine sizes*, leave it at the default or select the desired size depending on the application.\n\n9. Put the *username* and *password* (Keep this safe).\n\n<h2 style=\"padding-bottom:1rem\">Integrating the Virtual Machine with Your Network Security Group</h2>\n\nIn the next steps, we would be configuring the VMs NSG, this can as well be integrated with the newly created resource group so you do not have to create an NSG for individual resources within a resource group. To do this follow the steps below.\n\n1. Now it has the inbound ports. By default, allow selected ports to keep it as RDP for now.\n\n2. The licensing will probably be only applicable if you have this special Windows license.\n\n3. Click *Click Review and Create*.\n\n4. Once the validation is completed and there are no errors, hit *Create*.\n\n<h2 style=\"padding-bottom:1rem\">Connecting to the Virtual Machine</h2>\n\nOnce the provisioning is completed, we can then connect to the VM via RDP / ssh to configure our web server. To connect to the VM follow the steps below.\n\n1. Navigate to the newly created resource.\n\n2. Select the virtual machine, click *Connect* and select the option for RDP to download the RDP file.\n\n3. Open the *RDP file* and click connect.\n\n4. Try and utilize the credentials created earlier.\n\n<h2 style=\"padding-bottom:1rem\">Setting up the server Manager</h2>\n\nTo add a role from the server manager. You can either do this from *Add roles and features* or *Manage* (top right corner).\n\n1. Select the option *Add roles and Features*.\n\n2. Click *Next* and keep it at the default setting, *role-based or feature-based installation*.\n\n3. Click *Next* and keep *Server* as *{Server name used in step 4 above}*.\n\n4. Scroll down to *Web server IIS*. Click *Add feature* and click *Next*.\n\n5. Keep clicking *Next* and click *Install*.\n\n6. Once successfully installed, click *close*.\n\n7. Navigate back to *Tools*, click *Internet services IIS manager* to access the installed web service.\n\n8. To add a custom page, right-click *Sites*, and then switch over to content view, under website.\n\n<h2 style=\"padding-bottom:1rem\">Setting up the server Manager</h2>\n\n1. Access the file explorer, and then navigate to the directory that has your web content. From there, click *PC*, click *Windows*, click *Inetpub* then click *wwwroot*.\n\n2. Right-click in an empty area, and create a new text file.\n\n3. Type in \"Server says hello\" as an example.\n\n4. Click *File*, choose *Save As* \"index.html\" and click save.\n\nTo  see the webpage\n\n1. Go back to the portal, and click *Home*, Click *Virtual machines* under *Azure services*.\n\n2. Select the virtual machine *your server name*.\n\n3. Under *networking*, click *Add an inbound port rule*\n\n4. *Source*: \"any.\n\n5. *Source port ranges*: \"*\"\n\n6. *Destination*: any.\n\n7. *Destination port ranges*: 80, 443.\n\n8. *Protocol*: \"any\"\n\n9. Your priority numbers are going to be the opposite, so the lower the number, the higher priority. Enter \"HTTP access\" below Name\n\n10. Hit *add*.\n\nOnce the new rule has been created you will receive a notification showing the rule was successfully added. You can test the website by going to the public IP address of the VM, this would load the index.html file created earlier.\n"}]